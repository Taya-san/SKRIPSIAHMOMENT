{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87a0406",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import transformers\n",
    "from datasets import load_dataset\n",
    "import sklearn.model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1ebaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MambaFullConfig(transformers.PretrainedConfig):\n",
    "    model_type = \"mamba_full\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_model=768,        # Mamba hidden size\n",
    "        num_classes=2,      # Sentiment classes\n",
    "        num_clusters=3,     # DEKM clusters\n",
    "        latent_dim=128,     # The Z dimension\n",
    "        backbone_model=\"state-spaces/mamba-130m-hf\",\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.d_model = d_model\n",
    "        self.num_classes = num_classes\n",
    "        self.num_clusters = num_clusters\n",
    "        self.latent_dim = latent_dim\n",
    "        self.backbone_model = backbone_model\n",
    "        super().__init__(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d7f409",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class FullOutput(transformers.modelling_outputs.ModelOutput):\n",
    "    loss: torch.FloatTensor | None      # ðŸš¨ TRAINER LOOKS FOR THIS!\n",
    "    logits: torch.FloatTensor = None              # Sentiment\n",
    "    reconstruction: torch.FloatTensor = None      # Autoencoder output\n",
    "    latent_z: torch.FloatTensor = None            # The compressed code\n",
    "    cluster_logits: torch.FloatTensor | None # For DEKM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529219e5",
   "metadata": {},
   "outputs": [],
   "source": [
    " -a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a58041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tell AutoConfig: \"If you see 'mamba_hydra', use my Config class\"\n",
    "transformers.AutoConfig.register(\"mamba_full\", MambaFullConfig)\n",
    "\n",
    "# Tell AutoModel: \"If the config is MambaHydraConfig, use my Model class\"\n",
    "transformers.AutoModel.register(MambaFullConfig, MambaFull)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
