{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0475dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260833a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall -y torch torchvision torchaudio mamba-ssm causal-conv1d\n",
    "\n",
    "!pip install torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "!pip install https://github.com/Dao-AILab/causal-conv1d/releases/download/v1.6.0/causal_conv1d-1.6.0+cu12torch2.5cxx11abiFALSE-cp312-cp312-linux_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495d055a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install https://github.com/state-spaces/mamba/releases/download/v.2.3.0/mamba_ssm-2.3.0+cu12torch2.5cxx11abiFALSE-cp312-cp312-linux_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9acde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/Taya-san/SKRIPSIAHMOMENT.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a786d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87a0406",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import transformers\n",
    "from transformers import AutoModel, AutoConfig, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "import sklearn.model_selection\n",
    "import mamba_ssm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f97a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mamba_quin import MambaQuin, MambaQuinConfig\n",
    "from utils import train_modelnoclt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "485f7e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configuration_mamba import MambaQuinConfig\n",
    "from modelling_mamba import MambaQuin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "097f22ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "AutoConfig.register(\"mamba_quin\", MambaQuinConfig)\n",
    "AutoModel.register(MambaQuinConfig, MambaQuin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39f2ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
      "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
      "You are not authenticated with the Hugging Face Hub in this notebook.\n",
      "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e250ea84ef64403d9c6035b9a19fcd88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/895 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0c0f27f419848ccbf7ad453fab03722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/517M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The fast path is not available because one of `(selective_state_update, selective_scan_fn, causal_conv1d_fn, causal_conv1d_update, mamba_inner_fn)` is None. Falling back to the sequential implementation of Mamba, as use_mambapy is set to False. To install follow https://github.com/state-spaces/mamba/#installation for mamba-ssm and install the kernels library using `pip install kernels` or https://github.com/Dao-AILab/causal-conv1d for causal-conv1d. For the mamba.py backend, follow https://github.com/alxndrTL/mamba.py.\n"
     ]
    }
   ],
   "source": [
    "config = MambaQuinConfig(\n",
    "    latent_dim = 128,\n",
    ")\n",
    "\n",
    "model = MambaQuin(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049ea8bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
